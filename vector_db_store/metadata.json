{"ids": ["38dacda2-8a87-45bd-8fa1-9a548db76db7", "4d4aecb9-ff6e-48b9-9901-fcb81b035d49", "a917dfe1-fe66-4a5b-8348-08202b3c4e9a", "2647a741-666c-40de-b377-ff1676d2060f", "4a757ca8-551e-4cb4-89b1-a8f6b6aa3289", "496ccba0-b8d3-4b82-920e-81888f3839bd", "345a4a9e-d271-4c86-adee-eeb9dfd79db3", "0a016f2b-e14d-4b26-95ad-58b64782fffd", "11206497-b707-4cfa-ac04-8f2d2d855ca1", "060d3001-8dc8-4e7e-abbe-d49766a00b78", "ef292b41-6e2b-4080-af63-be177883ff61", "2d47575b-860a-45f8-953d-4db6c9c6360a", "03dcfd4c-75dc-4e81-b515-46e2ea4c496e", "3147d995-86d3-4bff-9823-8357d93974e3", "5f27a6d8-79d2-47b8-90bd-d15e5d7487ef", "p1", "p2", "p3", "p1", "p2", "p3", "sample_crud_updated.txt_p1", "sample_crud_updated.txt_p1", "sample.txt_p1", "sample.txt_p2", "sample.txt_p3", "sample.txt_p1", "sample.txt_p2", "sample.txt_p3", "sample.txt_p1", "sample.txt_p2", "sample.txt_p3", "sample.txt_p1", "sample.txt_p2", "sample.txt_p3", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 2.docx_p1", "blog 2.docx_p2", "blog 2.docx_p3", "blog 2.docx_p4", "blog 2.docx_p5", "blog 2.docx_p6", "blog 2.docx_p7", "blog 2.docx_p8", "blog 2.docx_p9", "blog 2.docx_p10", "blog 2.docx_p11", "blog 2.docx_p12", "blog 2.docx_p13", "blog 2.docx_p14", "blog 2.docx_p15", "blog 2.docx_p16", "blog 2.docx_p17", "blog 2.docx_p18", "blog 2.docx_p19", "blog 2.docx_p20", "blog 2.docx_p21", "blog 2.docx_p22", "blog 2.docx_p23", "blog 2.docx_p24", "blog 2.docx_p25", "blog 2.docx_p26", "blog 2.docx_p27", "blog 2.docx_p28", "blog 2.docx_p29", "blog 2.docx_p30", "blog 2.docx_p31", "blog 2.docx_p32", "blog 2.docx_p33", "blog 2.docx_p34", "blog 2.docx_p35", "ai resume.pdf_p1", "ai resume.pdf_p2", "ai resume.pdf_p3", "ai resume.pdf_p4", "ai resume.pdf_p5", "ai resume.pdf_p6", "ai resume.pdf_p7", "ai resume.pdf_p8", "ai resume.pdf_p9", "ai resume.pdf_p10", "ai resume.pdf_p11", "ai resume.pdf_p12", "ai resume.pdf_p13", "ai resume.pdf_p14", "ai resume.pdf_p15", "ai resume.pdf_p16", "ai resume.pdf_p17", "ai resume.pdf_p18", "ai resume.pdf_p19", "ai resume.pdf_p20", "ai resume.pdf_p21", "ai resume.pdf_p22", "ai resume.pdf_p23", "ai resume.pdf_p24", "ai resume.pdf_p25", "ai resume.pdf_p26", "ai resume.pdf_p27", "ai resume.pdf_p28", "ai resume.pdf_p29", "ai resume.pdf_p30", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "blog 1.docx_p1", "blog 1.docx_p2", "blog 1.docx_p3", "blog 1.docx_p4", "blog 1.docx_p5", "blog 1.docx_p6", "blog 1.docx_p7", "blog 1.docx_p8", "blog 1.docx_p9", "blog 1.docx_p10", "blog 1.docx_p11", "blog 1.docx_p12", "blog 1.docx_p13", "blog 1.docx_p14", "blog 1.docx_p15", "blog 1.docx_p16", "blog 1.docx_p17", "blog 1.docx_p18", "blog 1.docx_p19", "blog 1.docx_p20", "blog 1.docx_p21", "blog 1.docx_p22", "blog 1.docx_p23", "blog 1.docx_p24", "blog 1.docx_p25", "blog 1.docx_p26", "blog 1.docx_p27", "blog 1.docx_p28", "blog 1.docx_p29", "blog 1.docx_p30", "blog 1.docx_p31", "blog 1.docx_p32", "blog 1.docx_p33", "blog 1.docx_p34", "blog 1.docx_p35", "blog 1.docx_p36", "blog 1.docx_p37", "blog 1.docx_p38", "integration_test_html.txt_p1", "integration_test_html.txt_p2", "integration_test_html.txt_p3", "integration_test_html.txt_p4", "integration_test_html.txt_p5", "integration_test_html.txt_p6", "integration_test_html.txt_p7", "integration_test_html.txt_p8", "integration_test_markdown.txt_p1", "integration_test_text.txt_p1", "integration_test_html.txt_p1", "integration_test_html.txt_p2", "integration_test_html.txt_p3", "integration_test_html.txt_p4", "integration_test_html.txt_p5", "integration_test_html.txt_p6", "integration_test_html.txt_p7", "integration_test_html.txt_p8", "integration_test_markdown.txt_p1", "integration_test_text.txt_p1", "rag.docx_p1", "rag.docx_p2", "rag.docx_p3", "rag.docx_p4", "rag.docx_p5", "rag.docx_p6", "rag.docx_p7", "rag.docx_p8", "rag.docx_p9", "rag.docx_p10", "rag.docx_p11", "rag.docx_p12", "rag.docx_p13", "rag.docx_p14", "rag.docx_p15", "rag.docx_p16", "rag.docx_p17", "rag.docx_p18", "rag.docx_p19", "rag.docx_p20", "rag.docx_p21", "rag.docx_p22", "rag.docx_p23", "rag.docx_p24", "rag.docx_p25", "rag.docx_p26", "rag.docx_p27", "rag.docx_p28", "rag.docx_p29", "rag.docx_p30", "rag.docx_p31", "rag.docx_p32", "rag.docx_p33", "rag.docx_p34", "rag.docx_p35", "rag.docx_p36", "rag.docx_p37", "rag.docx_p38", "rag.docx_p39", "rag.docx_p40", "rag.docx_p41", "rag.docx_p42", "rag.docx_p43", "rag.docx_p44", "rag.docx_p45", "rag.docx_p46", "rag.docx_p47", "rag.docx_p48", "rag.docx_p49", "rag.docx_p50", "rag.docx_p51", "rag.docx_p52", "rag.docx_p53", "rag.docx_p54", "rag.docx_p55", "rag.docx_p56", "rag.docx_p57", "rag.docx_p58", "rag.docx_p59", "rag.docx_p60", "rag.docx_p61", "rag.docx_p62", "rag.docx_p63", "rag.docx_p64", "rag.docx_p65", "rag.docx_p66", "rag.docx_p67", "rag.docx_p68", "rag.docx_p69", "rag.docx_p70", "rag.docx_p71", "rag.docx_p72", "rag.docx_p73", "rag.docx_p74", "rag.docx_p75", "rag.docx_p76", "rag.docx_p77", "rag.docx_p78", "rag.docx_p79", "rag.docx_p80", "rag.docx_p81", "rag.docx_p82", "rag.docx_p83", "rag.docx_p84", "rag.docx_p85", "rag.docx_p86", "rag.docx_p87", "rag.docx_p88", "rag.docx_p89", "rag.docx_p90", "rag.docx_p91", "rag.docx_p92", "rag.docx_p93", "rag.docx_p94", "rag.docx_p95", "rag.docx_p96", "rag.docx_p97", "rag.docx_p98", "rag.docx_p99", "rag.docx_p100", "rag.docx_p101", "rag.docx_p102", "rag.docx_p103", "rag.docx_p104", "rag.docx_p105", "rag.docx_p106", "rag.docx_p107", "rag.docx_p108", "rag.docx_p109", "TextSplitting.docx_p1", "TextSplitting.docx_p2", "TextSplitting.docx_p3", "TextSplitting.docx_p4", "TextSplitting.docx_p5", "TextSplitting.docx_p6", "TextSplitting.docx_p7", "TextSplitting.docx_p8", "TextSplitting.docx_p9", "TextSplitting.docx_p10", "TextSplitting.docx_p11", "TextSplitting.docx_p12", "TextSplitting.docx_p13", "TextSplitting.docx_p14", "TextSplitting.docx_p15", "TextSplitting.docx_p16", "TextSplitting.docx_p17", "TextSplitting.docx_p18", "TextSplitting.docx_p19", "TextSplitting.docx_p20", "TextSplitting.docx_p21", "TextSplitting.docx_p22", "TextSplitting.docx_p23", "TextSplitting.docx_p24", "TextSplitting.docx_p25", "TextSplitting.docx_p26", "TextSplitting.docx_p27", "TextSplitting.docx_p28", "TextSplitting.docx_p29", "TextSplitting.docx_p30", "TextSplitting.docx_p31", "TextSplitting.docx_p32", "TextSplitting.docx_p33", "TextSplitting.docx_p34", "TextSplitting.docx_p35", "TextSplitting.docx_p36", "TextSplitting.docx_p37", "TextSplitting.docx_p38", "TextSplitting.docx_p39", "TextSplitting.docx_p40", "TextSplitting.docx_p41", "TextSplitting.docx_p42", "TextSplitting.docx_p43", "TextSplitting.docx_p44", "TextSplitting.docx_p45", "TextSplitting.docx_p46", "TextSplitting.docx_p47", "TextSplitting.docx_p48", "TextSplitting.docx_p49", "TextSplitting.docx_p50", "TextSplitting.docx_p51", "TextSplitting.docx_p52", "TextSplitting.docx_p53", "TextSplitting.docx_p54", "TextSplitting.docx_p55", "TextSplitting.docx_p56", "TextSplitting.docx_p57", "TextSplitting.docx_p58", "TextSplitting.docx_p59", "TextSplitting.docx_p60", "TextSplitting.docx_p61", "TextSplitting.docx_p62", "TextSplitting.docx_p63", "TextSplitting.docx_p64", "TextSplitting.docx_p65", "TextSplitting.docx_p66", "TextSplitting.docx_p67", "TextSplitting.docx_p68", "TextSplitting.docx_p69", "TextSplitting.docx_p70", "TextSplitting.docx_p71", "TextSplitting.docx_p72", "TextSplitting.docx_p73", "TextSplitting.docx_p74", "TextSplitting.docx_p75", "TextSplitting.docx_p76", "TextSplitting.docx_p77", "TextSplitting.docx_p78", "TextSplitting.docx_p79", "TextSplitting.docx_p80", "TextSplitting.docx_p81", "TextSplitting.docx_p82", "TextSplitting.docx_p83", "TextSplitting.docx_p84", "TextSplitting.docx_p85", "TextSplitting.docx_p86", "TextSplitting.docx_p87", "TextSplitting.docx_p88", "TextSplitting.docx_p89", "TextSplitting.docx_p90", "TextSplitting.docx_p91", "TextSplitting.docx_p92", "TextSplitting.docx_p93", "TextSplitting.docx_p94", "TextSplitting.docx_p95", "TextSplitting.docx_p96", "TextSplitting.docx_p97", "TextSplitting.docx_p98", "TextSplitting.docx_p99", "TextSplitting.docx_p100", "TextSplitting.docx_p101", "TextSplitting.docx_p102", "TextSplitting.docx_p103", "TextSplitting.docx_p104"], "payloads": {"38dacda2-8a87-45bd-8fa1-9a548db76db7": {"text": "doc 0"}, "4d4aecb9-ff6e-48b9-9901-fcb81b035d49": {"text": "doc 1"}, "a917dfe1-fe66-4a5b-8348-08202b3c4e9a": {"text": "doc 2"}, "2647a741-666c-40de-b377-ff1676d2060f": {"text": "doc 0"}, "4a757ca8-551e-4cb4-89b1-a8f6b6aa3289": {"text": "doc 1"}, "496ccba0-b8d3-4b82-920e-81888f3839bd": {"text": "doc 2"}, "345a4a9e-d271-4c86-adee-eeb9dfd79db3": {"text": "doc 0"}, "0a016f2b-e14d-4b26-95ad-58b64782fffd": {"text": "doc 1"}, "11206497-b707-4cfa-ac04-8f2d2d855ca1": {"text": "doc 2"}, "060d3001-8dc8-4e7e-abbe-d49766a00b78": {"text": "doc 0"}, "ef292b41-6e2b-4080-af63-be177883ff61": {"text": "doc 1"}, "2d47575b-860a-45f8-953d-4db6c9c6360a": {"text": "doc 2"}, "03dcfd4c-75dc-4e81-b515-46e2ea4c496e": {"text": "doc 0"}, "3147d995-86d3-4bff-9823-8357d93974e3": {"text": "doc 1"}, "5f27a6d8-79d2-47b8-90bd-d15e5d7487ef": {"text": "doc 2"}, "p1": {"paragraph_id": "p1", "source": "sample.txt", "text": "Alice is a software engineer at DevForge. She works on AI and automation projects."}, "p2": {"paragraph_id": "p2", "source": "sample.txt", "text": "Bob is the CTO of DevForge. He oversees all technology decisions and team management."}, "p3": {"paragraph_id": "p3", "source": "sample.txt", "text": "The company, DevForge, is located in Bangalore and specializes in AI SaaS products."}, "sample_crud_updated.txt_p1": {"doc_id": "sample_crud_updated.txt", "paragraph_id": "p1", "text": "This is an updated document for CRUD testing.\nNew content added.", "source": "sample_crud_updated.txt", "type": "txt", "metadata": {"filename": "sample_crud_updated.txt", "filesize": 65, "extension": ".txt"}}, "sample.txt_p1": {"doc_id": "sample.txt", "paragraph_id": "p1", "text": "Alice is a software engineer at DevForge. She works on AI and automation projects.", "source": "sample.txt", "type": "txt", "metadata": {"filename": "sample.txt", "filesize": 260, "extension": ".txt"}, "entity_ids": ["e_alice", "e_engineer", "e_devforge", "e_ai"]}, "sample.txt_p2": {"doc_id": "sample.txt", "paragraph_id": "p2", "text": "Bob is the CTO of DevForge. He oversees all technology decisions and team management.", "source": "sample.txt", "type": "txt", "metadata": {"filename": "sample.txt", "filesize": 260, "extension": ".txt"}, "entity_ids": ["e_bob", "e_cto", "e_devforge"]}, "sample.txt_p3": {"doc_id": "sample.txt", "paragraph_id": "p3", "text": "The company, DevForge, is located in Bangalore and specializes in AI SaaS products.", "source": "sample.txt", "type": "txt", "metadata": {"filename": "sample.txt", "filesize": 260, "extension": ".txt"}, "entity_ids": ["e_devforge", "e_bangalore", "e_saas", "e_the", "e_bangalore", "e_ai"]}, "blog 1.docx_p1": {"doc_id": "blog 1.docx", "paragraph_id": "p1", "text": "**Introduction:**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": []}, "blog 1.docx_p2": {"doc_id": "blog 1.docx", "paragraph_id": "p2", "text": "Imagine Sam, a 28-year-old entrepreneur running a growing e-commerce business.\nSam spends hours answering customer emails, rescheduling calls, and keeping track of orders. Even with productivity apps, Sam feels **overwhelmed** .", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_imagine", "e_sam", "e_even", "e_ai"]}, "blog 1.docx_p3": {"doc_id": "blog 1.docx", "paragraph_id": "p3", "text": "Now, imagine Sam had a digital teammate\u2014let\u2019s call it **SamBot** \u2014that:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_now"]}, "blog 1.docx_p4": {"doc_id": "blog 1.docx", "paragraph_id": "p4", "text": "- Reads customer queries automatically\n- Decides whether to answer, escalate, or reschedule\n- Updates the calendar and CRM\n- Responds politely in real time", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_reads", "e_decides", "e_updates", "e_responds"]}, "blog 1.docx_p5": {"doc_id": "blog 1.docx", "paragraph_id": "p5", "text": "That\u2019s not science fiction. That\u2019s an **AI Agentic System** .", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_that\u2019s", "e_agentic", "e_system**", "e_ai"]}, "blog 1.docx_p6": {"doc_id": "blog 1.docx", "paragraph_id": "p6", "text": "**\ud83e\udde0 What is an AI Agent?**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_what", "e_agent?**", "e_ai"]}, "blog 1.docx_p7": {"doc_id": "blog 1.docx", "paragraph_id": "p7", "text": "An AI agent is like a **digital assistant with a brain** . Unlike regular software that only executes fixed rules, an AI agent:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_unlike", "e_ai"]}, "blog 1.docx_p8": {"doc_id": "blog 1.docx", "paragraph_id": "p8", "text": "1. **Perceives** \u2192 Takes in inputs (emails, voice, calendar events)\n2. **Reasons** \u2192 Understands, plans, and decides the next step\n3. **Acts** \u2192 Executes tasks (send email, book slot, notify customer)", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_takes", "e_understands", "e_executes", "e_ai"]}, "blog 1.docx_p9": {"doc_id": "blog 1.docx", "paragraph_id": "p9", "text": "Here\u2019s a simple visual workflow:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_here\u2019s"]}, "blog 1.docx_p10": {"doc_id": "blog 1.docx", "paragraph_id": "p10", "text": "Input (email, voice, data) \u2192 Perception \u2192 Reasoning (Planning) \u2192 Action (Do the task)", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_input", "e_perception", "e_reasoning", "e_action", "e_ai"]}, "blog 1.docx_p11": {"doc_id": "blog 1.docx", "paragraph_id": "p11", "text": "\ud83d\udca1 **Human Analogy** : Think of a personal assistant.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_analogy**", "e_think"]}, "blog 1.docx_p12": {"doc_id": "blog 1.docx", "paragraph_id": "p12", "text": "- They **listen** to you (perception).\n- They **decide** how to handle tasks (reasoning).\n- They **actually do it** \u2014call clients, book tickets, send emails (action).", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_they", "e_ai"]}, "blog 1.docx_p13": {"doc_id": "blog 1.docx", "paragraph_id": "p13", "text": "AI agents mirror this exact cycle\u2014just digitally.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "blog 1.docx_p14": {"doc_id": "blog 1.docx", "paragraph_id": "p14", "text": "**\ud83d\udcca Case Study: Building SamBot (AI Scheduling + Support Agent)**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_case", "e_study", "e_building", "e_sambot", "e_scheduling", "e_support", "e_agent)**", "e_ai"]}, "blog 1.docx_p15": {"doc_id": "blog 1.docx", "paragraph_id": "p15", "text": "Let\u2019s break down **SamBot\u2019s workflow** in practice:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_let\u2019s"]}, "blog 1.docx_p16": {"doc_id": "blog 1.docx", "paragraph_id": "p16", "text": "**1. Perception**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_perception**"]}, "blog 1.docx_p17": {"doc_id": "blog 1.docx", "paragraph_id": "p17", "text": "- Reads an incoming email: *\u201cHi Sam, I need to reschedule our call to tomorrow 4 PM.\u201d*\n- Uses **natural language processing** to understand intent \u2192 *Reschedule request.*", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_reads", "e_sam", "e_pm.\u201d*", "e_uses", "e_an", "e_ai"]}, "blog 1.docx_p18": {"doc_id": "blog 1.docx", "paragraph_id": "p18", "text": "**2. Reasoning**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_reasoning**"]}, "blog 1.docx_p19": {"doc_id": "blog 1.docx", "paragraph_id": "p19", "text": "- Checks Sam\u2019s calendar availability.\n- Compares with customer preference.\n- If free \u2192 confirms reschedule.\n- If not free \u2192 proposes an alternative time.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_checks", "e_sam\u2019s", "e_compares", "e_\u2192", "e_ai"]}, "blog 1.docx_p20": {"doc_id": "blog 1.docx", "paragraph_id": "p20", "text": "**3. Action**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_action**"]}, "blog 1.docx_p21": {"doc_id": "blog 1.docx", "paragraph_id": "p21", "text": "- Updates the calendar.\n- Sends a polite confirmation email to the customer.\n- Logs the interaction in CRM for tracking.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_updates", "e_sends", "e_logs", "e_polite", "e_ai"]}, "blog 1.docx_p22": {"doc_id": "blog 1.docx", "paragraph_id": "p22", "text": "**4. Continuous Feedback Loop**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_continuous", "e_feedback", "e_loop**"]}, "blog 1.docx_p23": {"doc_id": "blog 1.docx", "paragraph_id": "p23", "text": "- Learns from mistakes (e.g., if customer rejects an automated slot).\n- Improves reasoning with feedback.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_learns", "e_improves"]}, "blog 1.docx_p24": {"doc_id": "blog 1.docx", "paragraph_id": "p24", "text": "**\ud83c\udfe2 Real-World Examples of Agentic Systems**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_real-world", "e_examples", "e_agentic", "e_systems**"]}, "blog 1.docx_p25": {"doc_id": "blog 1.docx", "paragraph_id": "p25", "text": "SamBot may sound futuristic, but agentic systems already exist today:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_sambot"]}, "blog 1.docx_p26": {"doc_id": "blog 1.docx", "paragraph_id": "p26", "text": "- **Customer Support Agents** (Zendesk bots, Intercom AI) \u2192 Resolve FAQs, escalate when needed.\n- **Scheduling Assistants** (x.ai, Motion AI, Clara) \u2192 Automate meetings without human effort.\n- **E-commerce Agents** \u2192 Recommend products, process returns, update inventory.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_support", "e_agents**", "e_intercom", "e_resolve", "e_faqs", "e_assistants**", "e_motion", "e_clara)", "e_automate", "e_recommend", "e_ai"]}, "blog 1.docx_p27": {"doc_id": "blog 1.docx", "paragraph_id": "p27", "text": "**\ud83c\udfa8 Visual Representation (Suggested Graphic)**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_visual", "e_representation", "e_graphic)**", "e_graph"]}, "blog 1.docx_p28": {"doc_id": "blog 1.docx", "paragraph_id": "p28", "text": "A simple diagram:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": []}, "blog 1.docx_p29": {"doc_id": "blog 1.docx", "paragraph_id": "p29", "text": "**Email Input \u2192 NLP (Perception) \u2192 Planner (Reasoning) \u2192 Calendar + CRM Update (Action)**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_input", "e_planner", "e_calendar", "e_update", "e_ai"]}, "blog 1.docx_p30": {"doc_id": "blog 1.docx", "paragraph_id": "p30", "text": "This mirrors how humans process tasks\u2014listen \u2192 think \u2192 act.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": []}, "blog 1.docx_p31": {"doc_id": "blog 1.docx", "paragraph_id": "p31", "text": "**\ud83d\udd79\ufe0f Interactive Activity (For Cohort Learners)**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_interactive", "e_activity", "e_cohort", "e_learners)**"]}, "blog 1.docx_p32": {"doc_id": "blog 1.docx", "paragraph_id": "p32", "text": "\ud83d\udc49 **Drag-and-Drop Challenge** : Match each step of SamBot\u2019s workflow to the right category:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_challenge**", "e_match", "e_sambot\u2019s"]}, "blog 1.docx_p33": {"doc_id": "blog 1.docx", "paragraph_id": "p33", "text": "- **Perception** : Reading email, analyzing intent\n- **Reasoning** : Checking calendar, deciding slot\n- **Action** : Sending email, updating CRM", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_reading", "e_checking", "e_sending", "e_ai"]}, "blog 1.docx_p34": {"doc_id": "blog 1.docx", "paragraph_id": "p34", "text": "**\u2753 Reflection Question for Readers**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_reflection", "e_question", "e_readers**"]}, "blog 1.docx_p35": {"doc_id": "blog 1.docx", "paragraph_id": "p35", "text": "Imagine you had your own personal AI agent:", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_imagine", "e_ai"]}, "blog 1.docx_p36": {"doc_id": "blog 1.docx", "paragraph_id": "p36", "text": "- What *daily repetitive task* would you offload first?\n(Examples: replying to \u201cWhere\u2019s my order?\u201d emails, setting reminders, or booking travel.)", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_what", "e_ai"]}, "blog 1.docx_p37": {"doc_id": "blog 1.docx", "paragraph_id": "p37", "text": "**\ud83d\udccc Key Takeaways**", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_takeaways**"]}, "blog 1.docx_p38": {"doc_id": "blog 1.docx", "paragraph_id": "p38", "text": "- AI agents go **beyond chatbots** \u2014they can perceive, reason, and act.\n- Designing them requires thinking in terms of **end-to-end workflows** , not single tasks.\n- Case studies like SamBot make it easy to see how agentic systems can transform productivity.", "source": "blog 1.docx", "type": "docx", "metadata": {"filename": "blog 1.docx", "filesize": 18890, "extension": ".docx"}, "entity_ids": ["e_designing", "e_case", "e_sambot", "e_ai"]}, "blog 2.docx_p1": {"doc_id": "blog 2.docx", "paragraph_id": "p1", "text": "**Introduction: Imagine This\u2026**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_imagine", "e_this\u2026**"]}, "blog 2.docx_p2": {"doc_id": "blog 2.docx", "paragraph_id": "p2", "text": "You wake up, and your digital assistant has already:", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": []}, "blog 2.docx_p3": {"doc_id": "blog 2.docx", "paragraph_id": "p3", "text": "- Booked a cab to your office\n- Moved your morning meeting to the afternoon because of a traffic jam\n- Answered a few customer queries overnight\n- Suggested a coffee deal nearby", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_booked", "e_moved", "e_answered", "e_suggested"]}, "blog 2.docx_p4": {"doc_id": "blog 2.docx", "paragraph_id": "p4", "text": "You didn\u2019t ask. It just *happened* .\nThat\u2019s the power of **AI agentic systems** working behind the scenes.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_that\u2019s", "e_ai"]}, "blog 2.docx_p5": {"doc_id": "blog 2.docx", "paragraph_id": "p5", "text": "**\ud83d\udd0e What Are Agentic Systems?**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_what", "e_agentic", "e_systems?**"]}, "blog 2.docx_p6": {"doc_id": "blog 2.docx", "paragraph_id": "p6", "text": "Agentic systems are **AI-powered entities that operate independently** , not just reacting to commands but **planning, coordinating, and executing tasks** to achieve goals.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_agentic", "e_ai"]}, "blog 2.docx_p7": {"doc_id": "blog 2.docx", "paragraph_id": "p7", "text": "They differ from simple bots because:", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_they"]}, "blog 2.docx_p8": {"doc_id": "blog 2.docx", "paragraph_id": "p8", "text": "- Bots = rule-based scripts (\u201cif A happens, do B\u201d).\n- Agents = autonomous problem-solvers with memory, reasoning, and adaptability.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_bots", "e_b\u201d)", "e_agents"]}, "blog 2.docx_p9": {"doc_id": "blog 2.docx", "paragraph_id": "p9", "text": "\ud83d\udca1 **Human Analogy** :", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_analogy**"]}, "blog 2.docx_p10": {"doc_id": "blog 2.docx", "paragraph_id": "p10", "text": "- A bot is like a vending machine\u2014you push a button, it gives you what you want.\n- An agent is like a restaurant waiter\u2014he understands your order, suggests sides, checks availability, and brings the food.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "blog 2.docx_p11": {"doc_id": "blog 2.docx", "paragraph_id": "p11", "text": "**\ud83c\udfe2 Real-World Examples**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_real-world", "e_examples**"]}, "blog 2.docx_p12": {"doc_id": "blog 2.docx", "paragraph_id": "p12", "text": "**1. Customer Support Agents**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_customer", "e_support", "e_agents**"]}, "blog 2.docx_p13": {"doc_id": "blog 2.docx", "paragraph_id": "p13", "text": "- **What they do** : Handle queries like *\u201cWhere\u2019s my order?\u201d* , escalate complex issues, and suggest solutions.\n- **Example** : Intercom\u2019s AI bot, which resolves FAQs autonomously.\n- **Benefit** : Saves human agents\u2019 time for complex cases.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_handle", "e_intercom\u2019s", "e_faqs", "e_saves", "e_ai"]}, "blog 2.docx_p14": {"doc_id": "blog 2.docx", "paragraph_id": "p14", "text": "**2. Scheduling Assistants**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_scheduling", "e_assistants**"]}, "blog 2.docx_p15": {"doc_id": "blog 2.docx", "paragraph_id": "p15", "text": "- **What they do** : Negotiate meeting times, sync across calendars, and reschedule conflicts.\n- **Example** : x.ai (Amy the AI assistant), Motion AI.\n- **Benefit** : Removes endless back-and-forth emails.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_negotiate", "e_motion", "e_removes", "e_ai"]}, "blog 2.docx_p16": {"doc_id": "blog 2.docx", "paragraph_id": "p16", "text": "**3. E-commerce Shopping Agents**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_e-commerce", "e_shopping", "e_agents**"]}, "blog 2.docx_p17": {"doc_id": "blog 2.docx", "paragraph_id": "p17", "text": "- **What they do** : Compare products, check reviews, find discounts, and add items to cart.\n- **Example** : Shopify AI plugins, ChatGPT-powered shopping assistants.\n- **Benefit** : Saves users hours of research and decision fatigue.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_compare", "e_shopify", "e_chatgpt-powered", "e_saves", "e_ai"]}, "blog 2.docx_p18": {"doc_id": "blog 2.docx", "paragraph_id": "p18", "text": "**4. Travel &amp; Lifestyle Agents**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_travel", "e_lifestyle", "e_agents**"]}, "blog 2.docx_p19": {"doc_id": "blog 2.docx", "paragraph_id": "p19", "text": "- **What they do** : Book flights, suggest itineraries, rebook if flights are delayed.\n- **Example** : Hopper AI, TripIt with AI features.\n- **Benefit** : Personalized travel without human effort.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_book", "e_hopper", "e_tripit", "e_personalized", "e_ai"]}, "blog 2.docx_p20": {"doc_id": "blog 2.docx", "paragraph_id": "p20", "text": "**\u2699\ufe0f Architectures: Single-Agent vs. Multi-Agent Systems**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_architectures", "e_single-agent", "e_multi-agent", "e_systems**"]}, "blog 2.docx_p21": {"doc_id": "blog 2.docx", "paragraph_id": "p21", "text": "**\ud83e\uddd1\u200d\ud83d\udcbb Single-Agent System**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_single-agent", "e_system**"]}, "blog 2.docx_p22": {"doc_id": "blog 2.docx", "paragraph_id": "p22", "text": "- **Definition** : One AI agent handles the entire workflow from start to finish.\n- **Example** : A scheduling assistant that receives a request, checks calendars, and books directly.\n- **Human Analogy** : A solo freelancer\u2014wears many hats, does everything themselves.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_analogy**", "e_ai"]}, "blog 2.docx_p23": {"doc_id": "blog 2.docx", "paragraph_id": "p23", "text": "**Pros:** Simple to build, easier to manage. **Cons:** Limited capabilities; not scalable for very complex tasks.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_simple", "e_limited"]}, "blog 2.docx_p24": {"doc_id": "blog 2.docx", "paragraph_id": "p24", "text": "**\ud83d\udc65 Multi-Agent System**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_multi-agent", "e_system**"]}, "blog 2.docx_p25": {"doc_id": "blog 2.docx", "paragraph_id": "p25", "text": "- **Definition** : Multiple specialized AI agents that collaborate.\n- **Example** : A travel booking system where:\n    - Agent A checks flights\n    - Agent B compares hotels\n    - Agent C manages payments\n    - Agent D handles cancellations\n- **Human Analogy** : A corporate team\u2014each member is an expert (finance, sales, marketing) and they coordinate.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_multiple", "e_agent", "e_analogy**", "e_ai"]}, "blog 2.docx_p26": {"doc_id": "blog 2.docx", "paragraph_id": "p26", "text": "**Pros:** Highly scalable, can handle complex tasks. **Cons:** Coordination is challenging, risk of \u201cagents arguing\u201d or looping.", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_highly", "e_coordination"]}, "blog 2.docx_p27": {"doc_id": "blog 2.docx", "paragraph_id": "p27", "text": "**\ud83c\udfa8 Visual Representation (Suggested Graphic)**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_visual", "e_representation", "e_graphic)**", "e_graph"]}, "blog 2.docx_p28": {"doc_id": "blog 2.docx", "paragraph_id": "p28", "text": "**Diagram Idea:**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_idea:**"]}, "blog 2.docx_p29": {"doc_id": "blog 2.docx", "paragraph_id": "p29", "text": "- Left side: *Single-Agent Workflow* (linear, one agent doing all steps).\n- Right side: *Multi-Agent Workflow* (team of agents passing tasks like a relay race).", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_left", "e_workflow*", "e_right"]}, "blog 2.docx_p30": {"doc_id": "blog 2.docx", "paragraph_id": "p30", "text": "**\ud83d\udd79\ufe0f Interactive Activity for Learners**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_interactive", "e_activity", "e_learners**"]}, "blog 2.docx_p31": {"doc_id": "blog 2.docx", "paragraph_id": "p31", "text": "\ud83d\udc49 **Scenario Challenge** :\nYou\u2019re designing an AI for a **restaurant booking service** .", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_challenge**", "e_you\u2019re", "e_ai"]}, "blog 2.docx_p32": {"doc_id": "blog 2.docx", "paragraph_id": "p32", "text": "- Should you use a **single-agent** (handles customer query \u2192 checks availability \u2192 confirms booking),\nor a **multi-agent system** (one agent handles queries, another checks availability, another manages payments)?", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_should", "e_\u2192", "e_ai"]}, "blog 2.docx_p33": {"doc_id": "blog 2.docx", "paragraph_id": "p33", "text": "**Reflection Question:** Which architecture do you think scales better when the restaurant also needs home delivery, loyalty programs, and payment integrations?", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_question:**", "e_which"]}, "blog 2.docx_p34": {"doc_id": "blog 2.docx", "paragraph_id": "p34", "text": "**\ud83d\udccc Key Takeaways**", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_takeaways**"]}, "blog 2.docx_p35": {"doc_id": "blog 2.docx", "paragraph_id": "p35", "text": "- **Agentic systems** are autonomous, adaptive, and goal-driven, unlike rule-based bots.\n- **Single-agent systems** = simple, efficient, but limited.\n- **Multi-agent systems** = powerful, scalable, but require coordination.\n- Real-world examples already exist in **customer support, scheduling, e-commerce, and travel** .", "source": "blog 2.docx", "type": "docx", "metadata": {"filename": "blog 2.docx", "filesize": 19098, "extension": ".docx"}, "entity_ids": ["e_real-world"]}, "ai resume.pdf_p1": {"doc_id": "ai resume.pdf", "paragraph_id": "p1", "text": "## PROFESSIONAL SUMMARY", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_professional", "e_summary"]}, "ai resume.pdf_p2": {"doc_id": "ai resume.pdf", "paragraph_id": "p2", "text": "Motivated AI and software development enthusiast with foundational knowledge in agentic AI systems, autonomous agents, and machine learning concepts. Skilled in Python, JavaScript, and full-stack development, with hands-on experience using no-code platforms like n8n and Make to rapidly prototype and deploy automation workflows. Passionate about building intelligent, goal-directed applications through a blend of traditional coding and \"vibe-based\" creative problem-solving. Fast learner with a strong drive to deliver innovative real-world solutions.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_motivated", "e_skilled", "e_python", "e_javascript", "e_make", "e_passionate", "e_fast", "e_ai", "e_machine_learning"]}, "ai resume.pdf_p3": {"doc_id": "ai resume.pdf", "paragraph_id": "p3", "text": "## EDUCATION", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_education"]}, "ai resume.pdf_p4": {"doc_id": "ai resume.pdf", "paragraph_id": "p4", "text": "12th Grade, I.M.S.T English Medium Higher Secondary School", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_grade", "e_i.m.s.t", "e_english", "e_medium", "e_higher", "e_secondary", "e_school"]}, "ai resume.pdf_p5": {"doc_id": "ai resume.pdf", "paragraph_id": "p5", "text": "Mar 2023", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": []}, "ai resume.pdf_p6": {"doc_id": "ai resume.pdf", "paragraph_id": "p6", "text": "## RELEVANT EXPERIENCE", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_relevant", "e_experience"]}, "ai resume.pdf_p7": {"doc_id": "ai resume.pdf", "paragraph_id": "p7", "text": "Software Developer, AI Automation Freelancer", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_software", "e_developer", "e_automation", "e_freelancer", "e_ai"]}, "ai resume.pdf_p8": {"doc_id": "ai resume.pdf", "paragraph_id": "p8", "text": "Bengaluru", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_bengaluru"]}, "ai resume.pdf_p9": {"doc_id": "ai resume.pdf", "paragraph_id": "p9", "text": "Jan 2023 - Present", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_present"]}, "ai resume.pdf_p10": {"doc_id": "ai resume.pdf", "paragraph_id": "p10", "text": "Designed and deployed custom solutions for small business clients.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_designed"]}, "ai resume.pdf_p11": {"doc_id": "ai resume.pdf", "paragraph_id": "p11", "text": "Integrated front-end and back-end logic for full-stack apps.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_integrated"]}, "ai resume.pdf_p12": {"doc_id": "ai resume.pdf", "paragraph_id": "p12", "text": "Gained practical experience in client communication and project delivery.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_gained", "e_ai"]}, "ai resume.pdf_p13": {"doc_id": "ai resume.pdf", "paragraph_id": "p13", "text": "## PROJECTS", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_projects"]}, "ai resume.pdf_p14": {"doc_id": "ai resume.pdf", "paragraph_id": "p14", "text": "## 1. AI Task Assistant with Voice Interface", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_task", "e_assistant", "e_voice", "e_interface", "e_ai"]}, "ai resume.pdf_p15": {"doc_id": "ai resume.pdf", "paragraph_id": "p15", "text": "Built an agentic AI application that uses LangChain and Vapi AI to call users and read their tasks from Google Tasks via voice. Implemented planner-executor pattern, API integrations, and dynamic memory handling. Technologies: Python, LangChain, Google Tasks API, Vapi AI", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_built", "e_langchain", "e_vapi", "e_google", "e_tasks", "e_implemented", "e_technologies", "e_python", "e_api", "e_ai"]}, "ai resume.pdf_p16": {"doc_id": "ai resume.pdf", "paragraph_id": "p16", "text": "## 2. Twitter Auto-Post Bot using LangChain", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_twitter", "e_auto-post", "e_langchain", "e_ai"]}, "ai resume.pdf_p17": {"doc_id": "ai resume.pdf", "paragraph_id": "p17", "text": "Developed an LLM-powered bot that posts daily tweets automatically using OpenAI and LangChain. Scheduled posting using cron jobs.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_developed", "e_llm-powered", "e_openai", "e_langchain", "e_scheduled", "e_ai"]}, "ai resume.pdf_p18": {"doc_id": "ai resume.pdf", "paragraph_id": "p18", "text": "Technologies: Python, LangChain, Twitter API, OpenAI API", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_technologies", "e_python", "e_langchain", "e_twitter", "e_api", "e_openai", "e_ai"]}, "ai resume.pdf_p19": {"doc_id": "ai resume.pdf", "paragraph_id": "p19", "text": "## 3. Online Cake Shop Web Application", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_online", "e_cake", "e_shop", "e_application"]}, "ai resume.pdf_p20": {"doc_id": "ai resume.pdf", "paragraph_id": "p20", "text": "Created a responsive e-commerce web app for ordering cakes. Implemented cart, product listing, and order features.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_created", "e_implemented"]}, "ai resume.pdf_p21": {"doc_id": "ai resume.pdf", "paragraph_id": "p21", "text": "Technologies: JavaScript, React, Node.js, MongoDB", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_technologies", "e_javascript", "e_react", "e_node.js", "e_mongodb"]}, "ai resume.pdf_p22": {"doc_id": "ai resume.pdf", "paragraph_id": "p22", "text": "Portfolio Website", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_portfolio", "e_website"]}, "ai resume.pdf_p23": {"doc_id": "ai resume.pdf", "paragraph_id": "p23", "text": "Built a personal portfolio site showcasing AI and web development projects with clean UI and smooth navigation.", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_built", "e_ai"]}, "ai resume.pdf_p24": {"doc_id": "ai resume.pdf", "paragraph_id": "p24", "text": "Technologies: HTML, CSS, JavaScript, Vercel", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_technologies", "e_html", "e_css", "e_javascript", "e_vercel"]}, "ai resume.pdf_p25": {"doc_id": "ai resume.pdf", "paragraph_id": "p25", "text": "## SKILLS", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_skills"]}, "ai resume.pdf_p26": {"doc_id": "ai resume.pdf", "paragraph_id": "p26", "text": "- Languages &amp; Tools: Python, JavaScript, TypeScript, C, C++, Java\n- AI &amp; Agentic Frameworks: LangChain, OpenAI API, Vapi AI, Gemini AI\n- Web Development: React.js, Node.js, Express.js, MongoDB, MySQL\n- Concepts: Autonomous Agents, LLM Integration, Tool Use, Memory, Planner-Executor Loops\n- Others: Git, Vercel, Postman, Webhooks, REST APIs\n- Soft Skills: Communication, Team Collaboration, Analytical Thinking", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_languages", "e_tools", "e_python", "e_javascript", "e_typescript", "e_c++", "e_java", "e_agentic", "e_frameworks", "e_langchain", "e_openai", "e_api", "e_vapi", "e_gemini", "e_development", "e_react.js", "e_node.js", "e_express.js", "e_mongodb", "e_mysql", "e_concepts", "e_autonomous", "e_agents", "e_integration", "e_tool", "e_use", "e_memory", "e_planner-executor", "e_loops", "e_others", "e_git", "e_vercel", "e_postman", "e_webhooks", "e_rest", "e_apis", "e_soft", "e_skills", "e_communication", "e_team", "e_collaboration", "e_analytical", "e_thinking", "e_ai"]}, "ai resume.pdf_p27": {"doc_id": "ai resume.pdf", "paragraph_id": "p27", "text": "## CERTIFICATIONS &amp; ACHIEVEMENTS", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_certifications", "e_achievements"]}, "ai resume.pdf_p28": {"doc_id": "ai resume.pdf", "paragraph_id": "p28", "text": "- Best Volunteer Award - Comic-Con &amp; Red Bull India\n- State-Level Badminton Player", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_best", "e_volunteer", "e_award", "e_comic-con", "e_bull", "e_india", "e_state-level", "e_badminton", "e_player"]}, "ai resume.pdf_p29": {"doc_id": "ai resume.pdf", "paragraph_id": "p29", "text": "## MD TOUFIQUE", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_toufique"]}, "ai resume.pdf_p30": {"doc_id": "ai resume.pdf", "paragraph_id": "p30", "text": "+91-9407716623 |  ahmedtoufiqkhan37@gmail.com Bangalore, India | \ud83c\udf10 https://project-henna-tau.vercel.app/", "source": "ai resume.pdf", "type": "pdf", "metadata": {"filename": "ai resume.pdf", "filesize": 44524, "extension": ".pdf"}, "entity_ids": ["e_bangalore", "e_india", "e_bangalore", "e_ai"]}, "integration_test_html.txt_p1": {"doc_id": "integration_test_html.txt", "paragraph_id": "p1", "text": "# Integration Test Document", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_integration", "e_test", "e_document"]}, "integration_test_html.txt_p2": {"doc_id": "integration_test_html.txt", "paragraph_id": "p2", "text": "## Section 1: Introduction", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_section", "e_introduction"]}, "integration_test_html.txt_p3": {"doc_id": "integration_test_html.txt", "paragraph_id": "p3", "text": "## Section 2: Features", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_section", "e_features"]}, "integration_test_html.txt_p4": {"doc_id": "integration_test_html.txt", "paragraph_id": "p4", "text": "## Section 3: Conclusion", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_section", "e_conclusion"]}, "integration_test_html.txt_p5": {"doc_id": "integration_test_html.txt", "paragraph_id": "p5", "text": "This is a test document for integration testing.", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": []}, "integration_test_html.txt_p6": {"doc_id": "integration_test_html.txt", "paragraph_id": "p6", "text": "It contains multiple paragraphs and structured content.", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_ai", "e_graph"]}, "integration_test_html.txt_p7": {"doc_id": "integration_test_html.txt", "paragraph_id": "p7", "text": "This document tests the complete integration pipeline.", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": []}, "integration_test_html.txt_p8": {"doc_id": "integration_test_html.txt", "paragraph_id": "p8", "text": "- Feature A: HTML processing\n- Feature B: Text extraction\n- Feature C: Structure preservation", "source": "integration_test_html.txt", "type": "txt", "metadata": {"filename": "integration_test_html.txt", "filesize": 379, "extension": ".txt"}, "entity_ids": ["e_feature", "e_html", "e_text", "e_structure"]}, "integration_test_markdown.txt_p1": {"doc_id": "integration_test_markdown.txt", "paragraph_id": "p1", "text": "# Research Document\n    \n    ## Abstract\n    This is a research document for testing the integration pipeline.\n    \n    ## Methodology\n    We used the following approach:\n    - Data collection\n    - Analysis\n    - Interpretation\n    \n    ## Results\n    The results show significant findings in the field.\n    \n    ## Conclusion\n    This research demonstrates the effectiveness of the system.", "source": "integration_test_markdown.txt", "type": "txt", "metadata": {"filename": "integration_test_markdown.txt", "filesize": 406, "extension": ".txt"}, "entity_ids": ["e_research", "e_document", "e_abstract", "e_methodology", "e_data", "e_analysis", "e_interpretation", "e_results", "e_conclusion"]}, "integration_test_text.txt_p1": {"doc_id": "integration_test_text.txt", "paragraph_id": "p1", "text": "Project Documentation\n \n Project Name: Integration Test Project\n Date: 2024-01-15\n \n Overview:\n This project tests the integration of unstructured data processing\n with the ingestion pipeline.\n \n Components:\n 1. Data Processor\n 2. Ingestion Pipeline\n 3. Vector Database\n 4. Graph Database\n \n Status: Testing in progress", "source": "integration_test_text.txt", "type": "txt", "metadata": {"filename": "integration_test_text.txt", "filesize": 334, "extension": ".txt"}, "entity_ids": ["e_project", "e_documentation", "e_name", "e_integration", "e_test", "e_date", "e_overview", "e_components", "e_data", "e_processor", "e_ingestion", "e_pipeline", "e_vector", "e_database", "e_graph", "e_status", "e_testing", "e_database", "e_graph", "e_vector"]}, "rag.docx_p1": {"doc_id": "rag.docx", "paragraph_id": "p1", "text": "**RAG Updated**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_updated**"]}, "rag.docx_p2": {"doc_id": "rag.docx", "paragraph_id": "p2", "text": "**Mastering RAG: From Theory to Practice with Retrieval-Augmented Generation**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_rag", "e_from", "e_theory", "e_practice", "e_retrieval-augmented", "e_generation**"]}, "rag.docx_p3": {"doc_id": "rag.docx", "paragraph_id": "p3", "text": "In the fast-paced world of generative AI, **Retrieval-Augmented Generation (RAG)** stands out as a transformative technique for creating intelligent, context-aware applications. By blending the power of Large Language Models (LLMs) with dynamic external data retrieval, RAG overcomes the shortcomings of traditional LLMs, such as limited access to private data, outdated knowledge, and hallucinations. This blog provides a thorough exploration of RAG\u2014what it is, why it matters, how it operates, and its edge over fine-tuning. To bridge theory and practice, we'll also include a hands-on project: building a RAG-based chatbot using LangChain to query a YouTube video transcript. This practical example will give you actionable insights to implement RAG in your own projects.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generation", "e_large", "e_language", "e_models", "e_llms", "e_rag\u2014what", "e_rag-based", "e_langchain", "e_youtube", "e_also", "e_ai"]}, "rag.docx_p4": {"doc_id": "rag.docx", "paragraph_id": "p4", "text": "**Why RAG? Addressing the Shortcomings of Traditional LLMs**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_rag", "e_addressing", "e_shortcomings", "e_traditional", "e_llms**"]}, "rag.docx_p5": {"doc_id": "rag.docx", "paragraph_id": "p5", "text": "LLMs like GPT-3 or LLaMA are massive transformer models trained on enormous datasets, encoding vast \"parametric knowledge\" in their parameters. They generate responses based on patterns from this training data when prompted. However, they face critical hurdles:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_llms", "e_gpt-3", "e_llama", "e_they", "e_however", "e_ai"]}, "rag.docx_p6": {"doc_id": "rag.docx", "paragraph_id": "p6", "text": "1. **Inaccessibility to Private Data** : LLMs can't handle queries about proprietary or unseen data. For instance, they won't know details from a confidential company report or video without additional context.\n2. **Knowledge Cutoff** : Training ends at a specific date, so LLMs miss post-training events. Queries like \"What's the latest on AI regulations in 2025?\" fall flat unless the model has real-time access or updates.\n3. **Hallucinations** : LLMs can confidently output false information, like inventing historical facts, due to their probabilistic generation process.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_private", "e_data**", "e_llms", "e_cutoff**", "e_training", "e_queries", "e_confidential", "e_ai"]}, "rag.docx_p7": {"doc_id": "rag.docx", "paragraph_id": "p7", "text": "Fine-tuning\u2014retraining on specialized data\u2014can mitigate these, but it's resource-intensive, requiring expertise, labeled data, and repeated efforts for updates. RAG offers a smarter, more agile alternative by fetching relevant data on-the-fly.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_fine-tuning\u2014retraining", "e_ai"]}, "rag.docx_p8": {"doc_id": "rag.docx", "paragraph_id": "p8", "text": "**What is RAG?**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_rag?**"]}, "rag.docx_p9": {"doc_id": "rag.docx", "paragraph_id": "p9", "text": "**Retrieval-Augmented Generation (RAG)** merges information retrieval with generative AI. It pulls in external context during inference, augmenting the LLM's internal knowledge without retraining. This leverages **in-context learning** , where LLMs adapt to prompts with examples or data provided at runtime.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generation", "e_llm's", "e_llms", "e_ai"]}, "rag.docx_p10": {"doc_id": "rag.docx", "paragraph_id": "p10", "text": "Imagine querying a long lecture video on machine learning: RAG retrieves specific transcript segments (e.g., on neural networks) and feeds them to the LLM, enabling precise answers grounded in the source material.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_imagine", "e_llm", "e_machine_learning", "e_neural_network"]}, "rag.docx_p11": {"doc_id": "rag.docx", "paragraph_id": "p11", "text": "**The RAG Pipeline: A Step-by-Step Breakdown**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_pipeline", "e_step-by-step", "e_breakdown**"]}, "rag.docx_p12": {"doc_id": "rag.docx", "paragraph_id": "p12", "text": "RAG follows a structured flow: **Indexing** , **Retrieval** , **Augmentation** , and **Generation** . We'll illustrate with an example of a chatbot for educational videos.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_we'll"]}, "rag.docx_p13": {"doc_id": "rag.docx", "paragraph_id": "p13", "text": "**1. Indexing: Preparing the Knowledge Base**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_indexing", "e_preparing", "e_knowledge", "e_base**"]}, "rag.docx_p14": {"doc_id": "rag.docx", "paragraph_id": "p14", "text": "This stage creates a searchable repository:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p15": {"doc_id": "rag.docx", "paragraph_id": "p15", "text": "- **Document Ingestion** : Load data, such as video transcripts or documents, using tools like LangChain's loaders (e.g., YouTubeLoader for transcripts).\n- **Text Chunking** : Split content into manageable pieces with overlap for context preservation. LangChain's RecursiveCharacterTextSplitter handles this, keeping chunks under token limits.\n- **Embedding Generation** : Transform chunks into vector embeddings using models like OpenAI's text-embedding-3-small for semantic representation.\n- **Vector Storage** : Save embeddings and metadata in a vector database like FAISS for fast similarity searches.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ingestion**", "e_load", "e_langchain's", "e_youtubeloader", "e_chunking**", "e_split", "e_recursivecharactertextsplitter", "e_generation**", "e_transform", "e_openai's", "e_storage**", "e_save", "e_faiss", "e_ai", "e_database", "e_vector"]}, "rag.docx_p16": {"doc_id": "rag.docx", "paragraph_id": "p16", "text": "**2. Retrieval: Matching Queries to Context**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_retrieval", "e_matching", "e_queries", "e_context**"]}, "rag.docx_p17": {"doc_id": "rag.docx", "paragraph_id": "p17", "text": "For a query like \"Explain gradient descent optimization\":", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p18": {"doc_id": "rag.docx", "paragraph_id": "p18", "text": "- Embed the query.\n- Search the vector store for similar embeddings (e.g., via cosine similarity).\n- Retrieve and rank top chunks, extracting relevant text (e.g., video segments on the topic).", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_embed", "e_search", "e_retrieve", "e_vector"]}, "rag.docx_p19": {"doc_id": "rag.docx", "paragraph_id": "p19", "text": "**3. Augmentation: Building the Enhanced Prompt**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_augmentation", "e_building", "e_enhanced", "e_prompt**"]}, "rag.docx_p20": {"doc_id": "rag.docx", "paragraph_id": "p20", "text": "Combine the query and retrieved context:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_combine"]}, "rag.docx_p21": {"doc_id": "rag.docx", "paragraph_id": "p21", "text": "You are a helpful assistant. Answer the question only from the provided context. If the context is insufficient, say \"I don\u2019t know\" to avoid hallucination.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_answer"]}, "rag.docx_p22": {"doc_id": "rag.docx", "paragraph_id": "p22", "text": "**Context**: [Relevant transcript chunks]", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p23": {"doc_id": "rag.docx", "paragraph_id": "p23", "text": "**Question**: [User query]", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p24": {"doc_id": "rag.docx", "paragraph_id": "p24", "text": "This grounds the LLM in factual data.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p25": {"doc_id": "rag.docx", "paragraph_id": "p25", "text": "**4. Generation: Crafting the Response**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generation", "e_crafting", "e_response**"]}, "rag.docx_p26": {"doc_id": "rag.docx", "paragraph_id": "p26", "text": "Feed the prompt to an LLM (e.g., GPT-4o-mini), which synthesizes a response using both its knowledge and the context, reducing errors.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_feed", "e_gpt-4o-mini)"]}, "rag.docx_p27": {"doc_id": "rag.docx", "paragraph_id": "p27", "text": "**RAG vs. Fine-Tuning: The Clear Advantages**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_fine-tuning", "e_clear", "e_advantages**"]}, "rag.docx_p28": {"doc_id": "rag.docx", "paragraph_id": "p28", "text": "RAG excels in handling private/recent data and curbing hallucinations without fine-tuning's drawbacks:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p29": {"doc_id": "rag.docx", "paragraph_id": "p29", "text": "- **Private Data** : Directly indexes your sources for tailored responses.\n- **Recent Data** : Easily update the vector store\u2014no retraining required.\n- **Hallucinations** : Context grounding and instructions minimize fabrications.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_data**", "e_directly", "e_easily", "e_context", "e_ai", "e_vector"]}, "rag.docx_p30": {"doc_id": "rag.docx", "paragraph_id": "p30", "text": "RAG is also more cost-effective, scalable, and beginner-friendly, needing no massive compute or datasets.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p31": {"doc_id": "rag.docx", "paragraph_id": "p31", "text": "**Real-World Use Cases for RAG**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_cases", "e_rag**"]}, "rag.docx_p32": {"doc_id": "rag.docx", "paragraph_id": "p32", "text": "- **Educational Tools** : Query course videos for targeted explanations.\n- **Customer Service** : Pull from knowledge bases for accurate support.\n- **Internal Knowledge Systems** : Search company docs for employee queries.\n- **Dynamic Content** : Handle real-time news or research summaries.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_tools**", "e_query", "e_service**", "e_pull", "e_knowledge", "e_systems**", "e_search", "e_content**", "e_handle", "e_search"]}, "rag.docx_p33": {"doc_id": "rag.docx", "paragraph_id": "p33", "text": "**Hands-On Project: Building a RAG Chatbot with LangChain**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_project", "e_building", "e_chatbot", "e_langchain**", "e_ai"]}, "rag.docx_p34": {"doc_id": "rag.docx", "paragraph_id": "p34", "text": "To make RAG tangible, let's implement a simple system using LangChain. This project creates a chatbot that answers questions about a YouTube video transcript (e.g., a TED Talk on AI). We'll use Python in a Colab environment, OpenAI for embeddings and generation, and FAISS as the vector store.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_langchain", "e_youtube", "e_talk", "e_ai)", "e_we'll", "e_python", "e_colab", "e_openai", "e_faiss", "e_ai", "e_vector"]}, "rag.docx_p35": {"doc_id": "rag.docx", "paragraph_id": "p35", "text": "**Prerequisites**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p36": {"doc_id": "rag.docx", "paragraph_id": "p36", "text": "- Install libraries: pip install -q youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv\n- Set your OpenAI API key: os.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_install", "e_openai", "e_ai"]}, "rag.docx_p37": {"doc_id": "rag.docx", "paragraph_id": "p37", "text": "**Step 1: Indexing (Ingestion, Chunking, Embedding, Storage)**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_indexing", "e_chunking", "e_embedding", "e_storage)**"]}, "rag.docx_p38": {"doc_id": "rag.docx", "paragraph_id": "p38", "text": "First, fetch and process the transcript:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_first"]}, "rag.docx_p39": {"doc_id": "rag.docx", "paragraph_id": "p39", "text": "import os", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p40": {"doc_id": "rag.docx", "paragraph_id": "p40", "text": "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_youtubetranscriptapi", "e_transcriptsdisabled"]}, "rag.docx_p41": {"doc_id": "rag.docx", "paragraph_id": "p41", "text": "from langchain.text_splitter import RecursiveCharacterTextSplitter", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter", "e_ai"]}, "rag.docx_p42": {"doc_id": "rag.docx", "paragraph_id": "p42", "text": "from langchain_openai import OpenAIEmbeddings", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_openaiembeddings", "e_ai"]}, "rag.docx_p43": {"doc_id": "rag.docx", "paragraph_id": "p43", "text": "from langchain_community.vectorstores import FAISS", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_faiss", "e_ai", "e_vector"]}, "rag.docx_p44": {"doc_id": "rag.docx", "paragraph_id": "p44", "text": "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\"", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p45": {"doc_id": "rag.docx", "paragraph_id": "p45", "text": "video_id = \"Gfr50f6ZBvo\"  # Example: TED Talk on AI (replace with your video ID)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_example", "e_talk", "e_ai"]}, "rag.docx_p46": {"doc_id": "rag.docx", "paragraph_id": "p46", "text": "try:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p47": {"doc_id": "rag.docx", "paragraph_id": "p47", "text": "transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_youtubetranscriptapi.get_transcript(video_id"]}, "rag.docx_p48": {"doc_id": "rag.docx", "paragraph_id": "p48", "text": "transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p49": {"doc_id": "rag.docx", "paragraph_id": "p49", "text": "print(\"Transcript fetched successfully.\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p50": {"doc_id": "rag.docx", "paragraph_id": "p50", "text": "except TranscriptsDisabled:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_transcriptsdisabled"]}, "rag.docx_p51": {"doc_id": "rag.docx", "paragraph_id": "p51", "text": "print(\"No captions available for this video.\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p52": {"doc_id": "rag.docx", "paragraph_id": "p52", "text": "# Chunk the transcript", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_chunk"]}, "rag.docx_p53": {"doc_id": "rag.docx", "paragraph_id": "p53", "text": "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter(chunk_size=1000"]}, "rag.docx_p54": {"doc_id": "rag.docx", "paragraph_id": "p54", "text": "chunks = splitter.create_documents([transcript])", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p55": {"doc_id": "rag.docx", "paragraph_id": "p55", "text": "print(f\"Created {len(chunks)} chunks.\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p56": {"doc_id": "rag.docx", "paragraph_id": "p56", "text": "# Generate embeddings and store in vector database", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generate", "e_database", "e_vector"]}, "rag.docx_p57": {"doc_id": "rag.docx", "paragraph_id": "p57", "text": "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_openaiembeddings(model=\"text-embedding-3-small\")", "e_ai"]}, "rag.docx_p58": {"doc_id": "rag.docx", "paragraph_id": "p58", "text": "vector_store = FAISS.from_documents(chunks, embeddings)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_faiss.from_documents(chunks", "e_ai", "e_vector"]}, "rag.docx_p59": {"doc_id": "rag.docx", "paragraph_id": "p59", "text": "print(\"Vector store created.\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_vector"]}, "rag.docx_p60": {"doc_id": "rag.docx", "paragraph_id": "p60", "text": "This ingests the transcript, splits it into chunks (e.g., ~1000 characters each with overlap), embeds them, and stores in FAISS.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_faiss", "e_ai"]}, "rag.docx_p61": {"doc_id": "rag.docx", "paragraph_id": "p61", "text": "**Step 2: Retrieval**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_retrieval**"]}, "rag.docx_p62": {"doc_id": "rag.docx", "paragraph_id": "p62", "text": "Set up a retriever to fetch relevant chunks:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p63": {"doc_id": "rag.docx", "paragraph_id": "p63", "text": "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_vector"]}, "rag.docx_p64": {"doc_id": "rag.docx", "paragraph_id": "p64", "text": "Test it: retriever.invoke(\"What is DeepMind?\") returns the top 4 matching chunks.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_test", "e_deepmind?\")"]}, "rag.docx_p65": {"doc_id": "rag.docx", "paragraph_id": "p65", "text": "**Step 3: Augmentation**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_augmentation**"]}, "rag.docx_p66": {"doc_id": "rag.docx", "paragraph_id": "p66", "text": "Define a prompt template:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_define"]}, "rag.docx_p67": {"doc_id": "rag.docx", "paragraph_id": "p67", "text": "from langchain_core.prompts import PromptTemplate", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_prompttemplate", "e_ai"]}, "rag.docx_p68": {"doc_id": "rag.docx", "paragraph_id": "p68", "text": "from langchain_openai import ChatOpenAI", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_chatopenai", "e_ai"]}, "rag.docx_p69": {"doc_id": "rag.docx", "paragraph_id": "p69", "text": "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_chatopenai(model=\"gpt-4o-mini\"", "e_ai"]}, "rag.docx_p70": {"doc_id": "rag.docx", "paragraph_id": "p70", "text": "prompt = PromptTemplate(", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_prompttemplate("]}, "rag.docx_p71": {"doc_id": "rag.docx", "paragraph_id": "p71", "text": "template=\"\"\"", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p72": {"doc_id": "rag.docx", "paragraph_id": "p72", "text": "You are a helpful assistant.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p73": {"doc_id": "rag.docx", "paragraph_id": "p73", "text": "Answer ONLY from the provided transcript context.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_answer", "e_only"]}, "rag.docx_p74": {"doc_id": "rag.docx", "paragraph_id": "p74", "text": "If the context is insufficient, just say you don't know.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p75": {"doc_id": "rag.docx", "paragraph_id": "p75", "text": "{context}", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p76": {"doc_id": "rag.docx", "paragraph_id": "p76", "text": "Question: {question}", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_question"]}, "rag.docx_p77": {"doc_id": "rag.docx", "paragraph_id": "p77", "text": "\"\"\",", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p78": {"doc_id": "rag.docx", "paragraph_id": "p78", "text": "input_variables=['context', 'question']", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p79": {"doc_id": "rag.docx", "paragraph_id": "p79", "text": ")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p80": {"doc_id": "rag.docx", "paragraph_id": "p80", "text": "For a question, retrieve context and build the prompt:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p81": {"doc_id": "rag.docx", "paragraph_id": "p81", "text": "question = \"Is nuclear fusion discussed in this video? If yes, what was said?\"", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p82": {"doc_id": "rag.docx", "paragraph_id": "p82", "text": "retrieved_docs = retriever.invoke(question)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p83": {"doc_id": "rag.docx", "paragraph_id": "p83", "text": "context_text = \"\\\\\\\\n\\\\\\\\n\".join(doc.page_content for doc in retrieved_docs)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p84": {"doc_id": "rag.docx", "paragraph_id": "p84", "text": "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p85": {"doc_id": "rag.docx", "paragraph_id": "p85", "text": "**Step 4: Generation**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generation**"]}, "rag.docx_p86": {"doc_id": "rag.docx", "paragraph_id": "p86", "text": "Generate the answer:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_generate"]}, "rag.docx_p87": {"doc_id": "rag.docx", "paragraph_id": "p87", "text": "answer = llm.invoke(final_prompt)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p88": {"doc_id": "rag.docx", "paragraph_id": "p88", "text": "print(answer.content)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p89": {"doc_id": "rag.docx", "paragraph_id": "p89", "text": "**Chaining It All Together**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_together**", "e_ai"]}, "rag.docx_p90": {"doc_id": "rag.docx", "paragraph_id": "p90", "text": "For a streamlined workflow, use LangChain's runnable chains:", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_langchain's", "e_ai"]}, "rag.docx_p91": {"doc_id": "rag.docx", "paragraph_id": "p91", "text": "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_runnableparallel", "e_runnablepassthrough", "e_runnablelambda", "e_ai"]}, "rag.docx_p92": {"doc_id": "rag.docx", "paragraph_id": "p92", "text": "from langchain_core.output_parsers import StrOutputParser", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_stroutputparser", "e_ai"]}, "rag.docx_p93": {"doc_id": "rag.docx", "paragraph_id": "p93", "text": "def format_docs(retrieved_docs):", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p94": {"doc_id": "rag.docx", "paragraph_id": "p94", "text": "return \"\\\\\\\\n\\\\\\\\n\".join(doc.page_content for doc in retrieved_docs)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p95": {"doc_id": "rag.docx", "paragraph_id": "p95", "text": "parallel_chain = RunnableParallel({", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_runnableparallel({", "e_ai"]}, "rag.docx_p96": {"doc_id": "rag.docx", "paragraph_id": "p96", "text": "'context': retriever | RunnableLambda(format_docs),", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_runnablelambda(format_docs)"]}, "rag.docx_p97": {"doc_id": "rag.docx", "paragraph_id": "p97", "text": "'question': RunnablePassthrough()", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_runnablepassthrough()"]}, "rag.docx_p98": {"doc_id": "rag.docx", "paragraph_id": "p98", "text": "})", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p99": {"doc_id": "rag.docx", "paragraph_id": "p99", "text": "parser = StrOutputParser()", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_stroutputparser()"]}, "rag.docx_p100": {"doc_id": "rag.docx", "paragraph_id": "p100", "text": "main_chain = parallel_chain | prompt | llm | parser", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p101": {"doc_id": "rag.docx", "paragraph_id": "p101", "text": "# Test the chain", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_test", "e_ai"]}, "rag.docx_p102": {"doc_id": "rag.docx", "paragraph_id": "p102", "text": "response = main_chain.invoke(\"Can you summarize the video?\")", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p103": {"doc_id": "rag.docx", "paragraph_id": "p103", "text": "print(response)", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p104": {"doc_id": "rag.docx", "paragraph_id": "p104", "text": "This chain retrieves context, augments the prompt, generates, and parses the output in one go.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_ai"]}, "rag.docx_p105": {"doc_id": "rag.docx", "paragraph_id": "p105", "text": "**Running the Project**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_project**"]}, "rag.docx_p106": {"doc_id": "rag.docx", "paragraph_id": "p106", "text": "Copy this into a Colab notebook, replace the video ID and API key, and experiment with queries. For example, asking about specific topics will pull precise transcript segments, demonstrating RAG's power in action.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_copy", "e_colab", "e_rag's"]}, "rag.docx_p107": {"doc_id": "rag.docx", "paragraph_id": "p107", "text": "This project shows how RAG can turn a static video into an interactive Q&amp;A tool. Extend it by adding more videos, using different embedders, or integrating with a UI like Streamlit.", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_q&amp;a", "e_extend", "e_streamlit"]}, "rag.docx_p108": {"doc_id": "rag.docx", "paragraph_id": "p108", "text": "**Conclusion**", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": []}, "rag.docx_p109": {"doc_id": "rag.docx", "paragraph_id": "p109", "text": "RAG is reshaping AI by making LLMs more reliable and adaptable. Through dynamic retrieval, it tackles real-world challenges efficiently, outpacing fine-tuning in many scenarios. With the hands-on project above, you're equipped to build your own RAG systems\u2014start experimenting and see the difference! Share your builds or questions in the comments. Happy coding!", "source": "rag.docx", "type": "docx", "metadata": {"filename": "rag.docx", "filesize": 23189, "extension": ".docx"}, "entity_ids": ["e_llms", "e_through", "e_with", "e_share", "e_happy", "e_ai"]}, "TextSplitting.docx_p1": {"doc_id": "TextSplitting.docx", "paragraph_id": "p1", "text": "**TextSplitting**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p2": {"doc_id": "TextSplitting.docx", "paragraph_id": "p2", "text": "**Text Splitting in LangChain: Smarter Chunking for Better AI**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_splitting", "e_langchain", "e_smarter", "e_chunking", "e_better", "e_ai**", "e_ai"]}, "TextSplitting.docx_p3": {"doc_id": "TextSplitting.docx", "paragraph_id": "p3", "text": "Large Language Models (LLMs) are powerful, but they come with a limitation: **context window size** . If you try to feed them a full book, PDF, or even a long blog post, you\u2019ll quickly hit those limits.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_large", "e_language", "e_models", "e_pdf"]}, "TextSplitting.docx_p4": {"doc_id": "TextSplitting.docx", "paragraph_id": "p4", "text": "This is why **text splitting** is one of the most important preprocessing steps when building Retrieval-Augmented Generation (RAG) pipelines, chatbots, or document question-answering systems. LangChain provides several strategies for splitting text into smaller, manageable chunks\u2014while still preserving meaning.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_retrieval-augmented", "e_generation", "e_langchain", "e_ai"]}, "TextSplitting.docx_p5": {"doc_id": "TextSplitting.docx", "paragraph_id": "p5", "text": "In this blog, we\u2019ll explore the **four main approaches to text splitting in LangChain** , along with practical code examples.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_langchain**", "e_ai"]}, "TextSplitting.docx_p6": {"doc_id": "TextSplitting.docx", "paragraph_id": "p6", "text": "**\ud83d\udd39 1. Length-Based Splitting**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_length-based", "e_splitting**"]}, "TextSplitting.docx_p7": {"doc_id": "TextSplitting.docx", "paragraph_id": "p7", "text": "This is the most basic form of text splitting. It simply divides text into chunks of a fixed size (e.g., 200 characters). While easy to implement, it doesn\u2019t care about **sentence or paragraph boundaries** , which can sometimes break meaning.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_while", "e_graph"]}, "TextSplitting.docx_p8": {"doc_id": "TextSplitting.docx", "paragraph_id": "p8", "text": "Example with a PDF loader:", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_example"]}, "TextSplitting.docx_p9": {"doc_id": "TextSplitting.docx", "paragraph_id": "p9", "text": "from langchain.text_splitter import CharacterTextSplitter", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_charactertextsplitter", "e_ai"]}, "TextSplitting.docx_p10": {"doc_id": "TextSplitting.docx", "paragraph_id": "p10", "text": "from langchain_community.document_loaders import PyPDFLoader", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_pypdfloader", "e_ai"]}, "TextSplitting.docx_p11": {"doc_id": "TextSplitting.docx", "paragraph_id": "p11", "text": "loader = PyPDFLoader('test.pdf')", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_pypdfloader('test.pdf')"]}, "TextSplitting.docx_p12": {"doc_id": "TextSplitting.docx", "paragraph_id": "p12", "text": "docs = loader.load()", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p13": {"doc_id": "TextSplitting.docx", "paragraph_id": "p13", "text": "splitter = CharacterTextSplitter(", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_charactertextsplitter("]}, "TextSplitting.docx_p14": {"doc_id": "TextSplitting.docx", "paragraph_id": "p14", "text": "chunk_size=200,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p15": {"doc_id": "TextSplitting.docx", "paragraph_id": "p15", "text": "chunk_overlap=0,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p16": {"doc_id": "TextSplitting.docx", "paragraph_id": "p16", "text": "separator=''", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p17": {"doc_id": "TextSplitting.docx", "paragraph_id": "p17", "text": ")", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p18": {"doc_id": "TextSplitting.docx", "paragraph_id": "p18", "text": "result = splitter.split_documents(docs)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p19": {"doc_id": "TextSplitting.docx", "paragraph_id": "p19", "text": "print(result[1].page_content)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p20": {"doc_id": "TextSplitting.docx", "paragraph_id": "p20", "text": "\u2705 Good for: fast splitting, very large datasets", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_good"]}, "TextSplitting.docx_p21": {"doc_id": "TextSplitting.docx", "paragraph_id": "p21", "text": "\u26a0\ufe0f Risk: may cut sentences or paragraphs awkwardly", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_risk", "e_graph"]}, "TextSplitting.docx_p22": {"doc_id": "TextSplitting.docx", "paragraph_id": "p22", "text": "**\ud83d\udd39 2. Text Structure\u2013Based Splitting**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_text", "e_structure\u2013based", "e_splitting**"]}, "TextSplitting.docx_p23": {"doc_id": "TextSplitting.docx", "paragraph_id": "p23", "text": "Instead of blindly chopping text, we can use **RecursiveCharacterTextSplitter** to split at natural boundaries\u2014paragraphs, sentences, and words. This produces chunks that are more **readable** and **context-preserving** .", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_instead", "e_graph"]}, "TextSplitting.docx_p24": {"doc_id": "TextSplitting.docx", "paragraph_id": "p24", "text": "from langchain.text_splitter import RecursiveCharacterTextSplitter", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter", "e_ai"]}, "TextSplitting.docx_p25": {"doc_id": "TextSplitting.docx", "paragraph_id": "p25", "text": "text = \"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p26": {"doc_id": "TextSplitting.docx", "paragraph_id": "p26", "text": "Space exploration has led to incredible scientific discoveries.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_space", "e_to"]}, "TextSplitting.docx_p27": {"doc_id": "TextSplitting.docx", "paragraph_id": "p27", "text": "From landing on the Moon to exploring Mars, humanity continues to push boundaries.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_from", "e_moon", "e_mars"]}, "TextSplitting.docx_p28": {"doc_id": "TextSplitting.docx", "paragraph_id": "p28", "text": "These missions expanded our knowledge of the universe and also drove innovations like GPS and medical imaging.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_these"]}, "TextSplitting.docx_p29": {"doc_id": "TextSplitting.docx", "paragraph_id": "p29", "text": "\"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p30": {"doc_id": "TextSplitting.docx", "paragraph_id": "p30", "text": "splitter = RecursiveCharacterTextSplitter(", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter("]}, "TextSplitting.docx_p31": {"doc_id": "TextSplitting.docx", "paragraph_id": "p31", "text": "chunk_size=500,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p32": {"doc_id": "TextSplitting.docx", "paragraph_id": "p32", "text": "chunk_overlap=0,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p33": {"doc_id": "TextSplitting.docx", "paragraph_id": "p33", "text": ")", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p34": {"doc_id": "TextSplitting.docx", "paragraph_id": "p34", "text": "chunks = splitter.split_text(text)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p35": {"doc_id": "TextSplitting.docx", "paragraph_id": "p35", "text": "print(len(chunks))", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p36": {"doc_id": "TextSplitting.docx", "paragraph_id": "p36", "text": "print(chunks)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p37": {"doc_id": "TextSplitting.docx", "paragraph_id": "p37", "text": "\u2705 Good for: general-purpose use cases, cleaner chunks", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_good"]}, "TextSplitting.docx_p38": {"doc_id": "TextSplitting.docx", "paragraph_id": "p38", "text": "\u26a0\ufe0f Slightly slower than simple character-based splitting", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_slightly"]}, "TextSplitting.docx_p39": {"doc_id": "TextSplitting.docx", "paragraph_id": "p39", "text": "**\ud83d\udd39 3. Document Structure\u2013Based Splitting**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_document", "e_structure\u2013based", "e_splitting**"]}, "TextSplitting.docx_p40": {"doc_id": "TextSplitting.docx", "paragraph_id": "p40", "text": "Some documents\u2014like Markdown, Python scripts, or academic papers\u2014have a clear structure. In these cases, splitting based on the **document\u2019s format** produces meaningful sections.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_some", "e_markdown", "e_python"]}, "TextSplitting.docx_p41": {"doc_id": "TextSplitting.docx", "paragraph_id": "p41", "text": "LangChain allows you to split by **language-aware rules** :", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_langchain", "e_ai"]}, "TextSplitting.docx_p42": {"doc_id": "TextSplitting.docx", "paragraph_id": "p42", "text": "**Markdown Example:**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_example:**"]}, "TextSplitting.docx_p43": {"doc_id": "TextSplitting.docx", "paragraph_id": "p43", "text": "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter", "e_language", "e_ai"]}, "TextSplitting.docx_p44": {"doc_id": "TextSplitting.docx", "paragraph_id": "p44", "text": "markdown_text = \"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p45": {"doc_id": "TextSplitting.docx", "paragraph_id": "p45", "text": "# Project: Smart Student Tracker", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_project", "e_smart", "e_student", "e_tracker"]}, "TextSplitting.docx_p46": {"doc_id": "TextSplitting.docx", "paragraph_id": "p46", "text": "A Python-based project to manage student data.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_python-based"]}, "TextSplitting.docx_p47": {"doc_id": "TextSplitting.docx", "paragraph_id": "p47", "text": "## Features", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_features"]}, "TextSplitting.docx_p48": {"doc_id": "TextSplitting.docx", "paragraph_id": "p48", "text": "- Add students", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p49": {"doc_id": "TextSplitting.docx", "paragraph_id": "p49", "text": "- View details", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_view", "e_ai"]}, "TextSplitting.docx_p50": {"doc_id": "TextSplitting.docx", "paragraph_id": "p50", "text": "- Check pass/fail status", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_check", "e_ai"]}, "TextSplitting.docx_p51": {"doc_id": "TextSplitting.docx", "paragraph_id": "p51", "text": "\"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p52": {"doc_id": "TextSplitting.docx", "paragraph_id": "p52", "text": "splitter = RecursiveCharacterTextSplitter.from_language(", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter.from_language("]}, "TextSplitting.docx_p53": {"doc_id": "TextSplitting.docx", "paragraph_id": "p53", "text": "language=Language.MARKDOWN,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p54": {"doc_id": "TextSplitting.docx", "paragraph_id": "p54", "text": "chunk_size=200,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p55": {"doc_id": "TextSplitting.docx", "paragraph_id": "p55", "text": "chunk_overlap=0,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p56": {"doc_id": "TextSplitting.docx", "paragraph_id": "p56", "text": ")", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p57": {"doc_id": "TextSplitting.docx", "paragraph_id": "p57", "text": "chunks = splitter.split_text(markdown_text)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p58": {"doc_id": "TextSplitting.docx", "paragraph_id": "p58", "text": "print(len(chunks))", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p59": {"doc_id": "TextSplitting.docx", "paragraph_id": "p59", "text": "print(chunks[0])", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p60": {"doc_id": "TextSplitting.docx", "paragraph_id": "p60", "text": "**Python Code Example:**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_code", "e_example:**"]}, "TextSplitting.docx_p61": {"doc_id": "TextSplitting.docx", "paragraph_id": "p61", "text": "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter", "e_language", "e_ai"]}, "TextSplitting.docx_p62": {"doc_id": "TextSplitting.docx", "paragraph_id": "p62", "text": "python_code = \"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p63": {"doc_id": "TextSplitting.docx", "paragraph_id": "p63", "text": "class Student:", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_student"]}, "TextSplitting.docx_p64": {"doc_id": "TextSplitting.docx", "paragraph_id": "p64", "text": "def __init__(self, name, grade):", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p65": {"doc_id": "TextSplitting.docx", "paragraph_id": "p65", "text": "self.name = name", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p66": {"doc_id": "TextSplitting.docx", "paragraph_id": "p66", "text": "self.grade = grade", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p67": {"doc_id": "TextSplitting.docx", "paragraph_id": "p67", "text": "\"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p68": {"doc_id": "TextSplitting.docx", "paragraph_id": "p68", "text": "splitter = RecursiveCharacterTextSplitter.from_language(", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_recursivecharactertextsplitter.from_language("]}, "TextSplitting.docx_p69": {"doc_id": "TextSplitting.docx", "paragraph_id": "p69", "text": "language=Language.PYTHON,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p70": {"doc_id": "TextSplitting.docx", "paragraph_id": "p70", "text": "chunk_size=300,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p71": {"doc_id": "TextSplitting.docx", "paragraph_id": "p71", "text": "chunk_overlap=0,", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p72": {"doc_id": "TextSplitting.docx", "paragraph_id": "p72", "text": ")", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p73": {"doc_id": "TextSplitting.docx", "paragraph_id": "p73", "text": "chunks = splitter.split_text(python_code)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p74": {"doc_id": "TextSplitting.docx", "paragraph_id": "p74", "text": "print(len(chunks))", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p75": {"doc_id": "TextSplitting.docx", "paragraph_id": "p75", "text": "print(chunks[1])", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p76": {"doc_id": "TextSplitting.docx", "paragraph_id": "p76", "text": "\u2705 Good for: structured content like blogs, notes, and source code", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_good"]}, "TextSplitting.docx_p77": {"doc_id": "TextSplitting.docx", "paragraph_id": "p77", "text": "\u26a0\ufe0f Requires specifying the correct language/format", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_requires"]}, "TextSplitting.docx_p78": {"doc_id": "TextSplitting.docx", "paragraph_id": "p78", "text": "**\ud83d\udd39 4. Semantic Meaning\u2013Based Splitting**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_semantic", "e_meaning\u2013based", "e_splitting**"]}, "TextSplitting.docx_p79": {"doc_id": "TextSplitting.docx", "paragraph_id": "p79", "text": "The most advanced method is **semantic splitting** , where AI decides where to break the text based on meaning. Instead of fixed character lengths, it uses **embeddings** to detect natural breakpoints.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_instead", "e_ai"]}, "TextSplitting.docx_p80": {"doc_id": "TextSplitting.docx", "paragraph_id": "p80", "text": "from langchain_experimental.text_splitter import SemanticChunker", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_semanticchunker", "e_ai"]}, "TextSplitting.docx_p81": {"doc_id": "TextSplitting.docx", "paragraph_id": "p81", "text": "from langchain_openai.embeddings import OpenAIEmbeddings", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_openaiembeddings", "e_ai"]}, "TextSplitting.docx_p82": {"doc_id": "TextSplitting.docx", "paragraph_id": "p82", "text": "from dotenv import load_dotenv", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p83": {"doc_id": "TextSplitting.docx", "paragraph_id": "p83", "text": "load_dotenv()", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p84": {"doc_id": "TextSplitting.docx", "paragraph_id": "p84", "text": "text_splitter = SemanticChunker(", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_semanticchunker("]}, "TextSplitting.docx_p85": {"doc_id": "TextSplitting.docx", "paragraph_id": "p85", "text": "OpenAIEmbeddings(),", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_openaiembeddings()", "e_ai"]}, "TextSplitting.docx_p86": {"doc_id": "TextSplitting.docx", "paragraph_id": "p86", "text": "breakpoint_threshold_type=\"standard_deviation\",", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p87": {"doc_id": "TextSplitting.docx", "paragraph_id": "p87", "text": "breakpoint_threshold_amount=3", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p88": {"doc_id": "TextSplitting.docx", "paragraph_id": "p88", "text": ")", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p89": {"doc_id": "TextSplitting.docx", "paragraph_id": "p89", "text": "sample = \"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p90": {"doc_id": "TextSplitting.docx", "paragraph_id": "p90", "text": "Farmers were planting seeds in the fields...", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_farmers"]}, "TextSplitting.docx_p91": {"doc_id": "TextSplitting.docx", "paragraph_id": "p91", "text": "The IPL is the biggest cricket league in the world...", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p92": {"doc_id": "TextSplitting.docx", "paragraph_id": "p92", "text": "Terrorism is a major global threat...", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_terrorism"]}, "TextSplitting.docx_p93": {"doc_id": "TextSplitting.docx", "paragraph_id": "p93", "text": "\"\"\"", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p94": {"doc_id": "TextSplitting.docx", "paragraph_id": "p94", "text": "docs = text_splitter.create_documents([sample])", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p95": {"doc_id": "TextSplitting.docx", "paragraph_id": "p95", "text": "print(len(docs))", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p96": {"doc_id": "TextSplitting.docx", "paragraph_id": "p96", "text": "print(docs)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": []}, "TextSplitting.docx_p97": {"doc_id": "TextSplitting.docx", "paragraph_id": "p97", "text": "\u2705 Good for: advanced RAG pipelines, knowledge bases", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_good"]}, "TextSplitting.docx_p98": {"doc_id": "TextSplitting.docx", "paragraph_id": "p98", "text": "\u26a0\ufe0f Requires embeddings (slower, higher cost, but much smarter)", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_requires"]}, "TextSplitting.docx_p99": {"doc_id": "TextSplitting.docx", "paragraph_id": "p99", "text": "**\ud83d\udd39 Choosing the Right Splitting Strategy**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_choosing", "e_right", "e_splitting", "e_strategy**"]}, "TextSplitting.docx_p100": {"doc_id": "TextSplitting.docx", "paragraph_id": "p100", "text": "- **Length-based** \u2192 Fastest, works when precision isn\u2019t critical\n- **Text structure\u2013based** \u2192 Best all-rounder, good for most use cases\n- **Document structure\u2013based** \u2192 Ideal for Markdown, source code, research papers\n- **Semantic splitting** \u2192 Most powerful, best for critical RAG systems", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_fastest", "e_best", "e_ideal", "e_markdown", "e_most"]}, "TextSplitting.docx_p101": {"doc_id": "TextSplitting.docx", "paragraph_id": "p101", "text": "**\u2705 Final Thoughts**", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_final", "e_thoughts**"]}, "TextSplitting.docx_p102": {"doc_id": "TextSplitting.docx", "paragraph_id": "p102", "text": "Text splitting may seem like a small preprocessing step, but it\u2019s the **foundation of building effective AI applications** . Poor splitting leads to poor retrieval, which means your LLM will struggle to answer questions accurately.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_text", "e_poor", "e_ai"]}, "TextSplitting.docx_p103": {"doc_id": "TextSplitting.docx", "paragraph_id": "p103", "text": "LangChain gives you multiple strategies\u2014from simple character-based to advanced semantic chunking\u2014so you can tailor your approach based on your content and use case.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_langchain", "e_ai"]}, "TextSplitting.docx_p104": {"doc_id": "TextSplitting.docx", "paragraph_id": "p104", "text": "\ud83d\ude80 In the next part of this series, we\u2019ll explore **Vector Stores** and how split text is stored and retrieved for intelligent search and Q&amp;A.", "source": "TextSplitting.docx", "type": "docx", "metadata": {"filename": "TextSplitting.docx", "filesize": 22165, "extension": ".docx"}, "entity_ids": ["e_stores**", "e_q&amp;a", "e_vector"]}}}